{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a closer look at color spaces\n",
    "\n",
    "You may have remembered we talked about images being stored in RGB (Red Green Blue) color Spaces. Let's take a look at that in OpenCV.\n",
    "\n",
    "### First thing to remember about OpenCV's RGB is that it's BGR (I know, this is annoying)\n",
    "\n",
    "Let's look at the image shape again. The '3L' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./images/pic.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the individual color levels for the first pixel (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BGR Values for the first 0,0 pixel\n",
    "cv2.imshow('image',image)\n",
    "cv2.waitKey()\n",
    "B, G, R = image[0,0] \n",
    "print (B, G, R)\n",
    "print (image.shape)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we convert it to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('./images/pic.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Convert to HSV (as you already had)\n",
    "HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Now you can safely use gray_img\n",
    "print(\"Gray image shape:\", gray_img.shape)\n",
    "print(\"Pixel value at (496, 600):\", gray_img[496, 600])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now only 2 dimensions. Each pixel coordinate has only one value (previously 3) with a range of 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another useful color space is HSV (Hue - Saturation - Value)\n",
    "Infact HSV is very useful in color filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread('./images/pic.jpg')\n",
    "\n",
    "# Show the original image\n",
    "cv2.imshow('Original image', image)\n",
    "\n",
    "# Show each BGR channel separately\n",
    "cv2.imshow('Blue channel', image[:, :, 0])\n",
    "cv2.imshow('Green channel', image[:, :, 1])\n",
    "cv2.imshow('Red channel', image[:, :, 2])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now explore lookng at individual channels in an RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('./images/pic.jpg')\n",
    "\n",
    "# Split channels\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "# Show channels\n",
    "cv2.imshow(\"Red Channel\", R)\n",
    "cv2.imshow(\"Green Channel\", G)\n",
    "cv2.imshow(\"Blue Channel\", B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Merge back to original\n",
    "merged = cv2.merge([B, G, R])\n",
    "cv2.imshow(\"Merged Original\", merged)\n",
    "\n",
    "# Amplify Blue and Green safely\n",
    "amplified_B = cv2.add(B, 100)\n",
    "amplified_G = cv2.add(G, 100)\n",
    "merged_boosted = cv2.merge([amplified_B, amplified_G, R])\n",
    "\n",
    "cv2.imshow(\"Merged with Blue+Green Amplified\", merged_boosted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m B, G, R = cv2.split(\u001b[43mimage\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Let's create a matrix of zeros \u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# with dimensions of the image h x w  \u001b[39;00m\n\u001b[32m      8\u001b[39m zeros = np.zeros(image.shape[:\u001b[32m2\u001b[39m], dtype = \u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "# Let's create a matrix of zeros \n",
    "# with dimensions of the image h x w  \n",
    "zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "\n",
    "cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can view a list of color converisons here, but keep in mind you won't ever use or need many of these\n",
    "\n",
    "http://docs.opencv.org/trunk/d7/d1b/group__imgproc__misc.html#ga4e0972be5de079fed4e3a10e24ef5ef0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "#### Directions: \n",
    "1. Load an image.  Create a filter (as a function) for images, similar to what your present in your cameras. Show and compare each images using different filters you created. Be creative and imaginative. Make sure that the filter adjusts/ corrects the original image.\n",
    "2. Create or load a grayscale image object. Try to revert it back to an assumed three-channeled image. Tip: Create individual layers and then combine. Additional Tip: You are free to use different values for RGB as long as it should return back to the original grayscale image.\n",
    "3. Convert and save a BnW image from the grayscale image you created. Save the file as BnW - SURNAME, FirstName.\n",
    "\n",
    "#### Activity\n",
    "1. Differentiate RGB and HSV. What do these things do? Is it possible to have one but not the other? \n",
    "2. Can I convert HSV images to RGB and vice versa?\n",
    "3. How are filters useful in image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# ---------------- FILTER FUNCTIONS ----------------\n",
    "def apply_sepia(img):\n",
    "    kernel = np.array([[0.272, 0.534, 0.131],\n",
    "                       [0.349, 0.686, 0.168],\n",
    "                       [0.393, 0.769, 0.189]])\n",
    "    sepia = cv2.transform(img, kernel)\n",
    "    return np.clip(sepia, 0, 255).astype(np.uint8)\n",
    "\n",
    "def apply_negative(img):\n",
    "    return 255 - img\n",
    "\n",
    "def apply_brightness(img, value=50):\n",
    "    return cv2.convertScaleAbs(img, alpha=1, beta=value)\n",
    "\n",
    "def apply_contrast(img, alpha=1.5):\n",
    "    return cv2.convertScaleAbs(img, alpha=alpha, beta=0)\n",
    "\n",
    "def apply_blur(img, ksize=15):\n",
    "    return cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "\n",
    "# ---------------- MAIN PHOTBOOTH ----------------\n",
    "class PhotoBooth:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"üì∏ Photobooth\")\n",
    "        self.image = None\n",
    "        self.filtered = {}\n",
    "\n",
    "        # Main menu\n",
    "        tk.Label(root, text=\"Welcome to Photobooth!\", font=(\"Arial\", 14)).pack(pady=10)\n",
    "        tk.Button(root, text=\"üì∑ Take Photo\", width=20, command=self.take_photo).pack(pady=5)\n",
    "        tk.Button(root, text=\"üñº Load Image\", width=20, command=self.load_image).pack(pady=5)\n",
    "        tk.Button(root, text=\"‚ùå Exit\", width=20, command=root.quit).pack(pady=5)\n",
    "\n",
    "    def take_photo(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imshow(\"Press SPACE to Capture, ESC to Exit\", frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:  # ESC\n",
    "                break\n",
    "            elif key == 32:  # SPACE\n",
    "                self.image = frame.copy()\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if self.image is not None:\n",
    "            self.open_editor()\n",
    "\n",
    "    def load_image(self):\n",
    "        path = filedialog.askopenfilename(title=\"Select an image\")\n",
    "        if path:\n",
    "            self.image = cv2.imread(path)\n",
    "            self.open_editor()\n",
    "\n",
    "    def open_editor(self):\n",
    "        # Editor window\n",
    "        editor = tk.Toplevel(self.root)\n",
    "        editor.title(\"üé® Edit Image\")\n",
    "\n",
    "        tk.Label(editor, text=\"Choose a filter to preview:\", font=(\"Arial\", 12)).pack(pady=10)\n",
    "\n",
    "        tk.Button(editor, text=\"Sepia\", width=20, command=lambda: self.show_filter(\"Sepia\", apply_sepia)).pack(pady=5)\n",
    "        tk.Button(editor, text=\"Negative\", width=20, command=lambda: self.show_filter(\"Negative\", apply_negative)).pack(pady=5)\n",
    "        tk.Button(editor, text=\"Brightness\", width=20, command=lambda: self.show_filter(\"Brightness\", lambda img: apply_brightness(img, 60))).pack(pady=5)\n",
    "        tk.Button(editor, text=\"Contrast\", width=20, command=lambda: self.show_filter(\"Contrast\", lambda img: apply_contrast(img, 1.8))).pack(pady=5)\n",
    "        tk.Button(editor, text=\"Blur\", width=20, command=lambda: self.show_filter(\"Blur\", apply_blur)).pack(pady=5)\n",
    "\n",
    "        tk.Button(editor, text=\"üíæ Save Collage\", width=20, command=self.save_collage).pack(pady=10)\n",
    "\n",
    "    def show_filter(self, name, func):\n",
    "        result = func(self.image)\n",
    "        self.filtered[name] = result\n",
    "        cv2.imshow(name, result)\n",
    "\n",
    "    def save_collage(self):\n",
    "        if self.image is None:\n",
    "            return\n",
    "\n",
    "        # Always include all filters\n",
    "        sepia = apply_sepia(self.image)\n",
    "        negative = apply_negative(self.image)\n",
    "        bright = apply_brightness(self.image, 60)\n",
    "        contrast = apply_contrast(self.image, 1.8)\n",
    "        blurred = apply_blur(self.image)\n",
    "\n",
    "        imgs = [self.image, sepia, negative, bright, contrast, blurred]\n",
    "\n",
    "        # Resize for collage\n",
    "        h, w = 250, 250\n",
    "        imgs = [cv2.resize(img, (w, h)) for img in imgs]\n",
    "\n",
    "        # Make 3x2 grid\n",
    "        row1 = np.hstack(imgs[0:3])\n",
    "        row2 = np.hstack(imgs[3:6])\n",
    "        collage = np.vstack([row1, row2])\n",
    "\n",
    "        # Show and save\n",
    "        cv2.imshow(\"Photobooth Collage\", collage)\n",
    "        cv2.imwrite(\"Photobooth_Collage.png\", collage)\n",
    "        print(\"‚úÖ Collage saved as Photobooth_Collage.png\")\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# ---------------- RUN PROGRAM ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PhotoBooth(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
